{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcthompson5@ad.wisc.edu/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, linregress\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove_VI.glv import *\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of folds\n",
    "n_splits = 20\n",
    "\n",
    "# import file names\n",
    "files = os.listdir(\"data/SET3_Thirdtrial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(df, species):\n",
    "    \n",
    "    # save measured and predicted values\n",
    "    exp_names = []\n",
    "    pred_species = []\n",
    "    pred = []\n",
    "    stdv = []\n",
    "    true = []\n",
    "\n",
    "    # pull just the community data\n",
    "    test_data = process_df_glove(df, species) \n",
    "\n",
    "    # plot the results\n",
    "    for exp, t_span, Y_m in test_data:\n",
    "\n",
    "        # predict \n",
    "        Y_p, Y_std, _, _ = model.predict(Y_m, t_span)\n",
    "        \n",
    "        # set NaN to zero\n",
    "        Y_p = np.nan_to_num(Y_p)\n",
    "        Y_std = np.nan_to_num(Y_std)\n",
    "        \n",
    "        ### prediction results for species that were present ###\n",
    "        inds_present = Y_m[0] > 0 \n",
    "        exp_names.append([exp]*sum(inds_present)*(Y_m.shape[0]-1))\n",
    "        pred_species.append(np.tile(np.vstack(species)[inds_present], Y_m.shape[0]-1).T.ravel())\n",
    "        true.append(Y_m[1:,inds_present].ravel())\n",
    "        pred.append(Y_p[1:,inds_present].ravel())\n",
    "        stdv.append(Y_std[1:,inds_present].ravel())\n",
    "                \n",
    "    # concatenate list\n",
    "    exp_names = np.concatenate(exp_names)\n",
    "    pred_species = np.concatenate(pred_species)\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "    stdv = np.concatenate(stdv)\n",
    "        \n",
    "    return exp_names, pred_species, true, pred, stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1147f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 72\n",
      "Updating posterior...\n",
      "Epoch 0, ELBO: -72008.352, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 10, ELBO: -26496.730, Slope: 1.000\n",
      "encountered 21 nans\n",
      "Epoch 20, ELBO: -9300.337, Slope: 0.435\n",
      "encountered 5 nans\n",
      "Epoch 30, ELBO: -4497.604, Slope: 0.305\n",
      "encountered 0 nans\n",
      "Epoch 40, ELBO: 1480.359, Slope: 0.235\n",
      "encountered 1 nans\n",
      "Epoch 50, ELBO: 6294.330, Slope: 0.191\n",
      "encountered 0 nans\n",
      "Epoch 60, ELBO: 8281.899, Slope: 0.157\n",
      "encountered 1 nans\n",
      "Epoch 70, ELBO: 11610.503, Slope: 0.134\n",
      "encountered 0 nans\n",
      "Epoch 80, ELBO: 12717.954, Slope: 0.116\n",
      "encountered 1 nans\n",
      "Epoch 90, ELBO: 12960.115, Slope: 0.100\n",
      "encountered 0 nans\n",
      "Epoch 100, ELBO: 13155.193, Slope: 0.144\n",
      "encountered 0 nans\n",
      "Epoch 110, ELBO: 13278.422, Slope: 0.186\n",
      "encountered 0 nans\n",
      "Epoch 120, ELBO: 13473.535, Slope: 0.132\n",
      "encountered 0 nans\n",
      "Epoch 130, ELBO: 13525.232, Slope: 0.084\n",
      "encountered 1 nans\n",
      "Epoch 140, ELBO: 13588.013, Slope: 0.051\n",
      "encountered 0 nans\n",
      "Epoch 150, ELBO: 13572.293, Slope: 0.030\n",
      "encountered 0 nans\n",
      "Epoch 160, ELBO: 13677.762, Slope: 0.013\n",
      "encountered 0 nans\n",
      "Epoch 170, ELBO: 13693.137, Slope: 0.007\n",
      "encountered 0 nans\n",
      "Epoch 180, ELBO: 13646.999, Slope: 0.005\n",
      "encountered 0 nans\n",
      "Epoch 190, ELBO: 13659.361, Slope: 0.004\n",
      "encountered 0 nans\n",
      "Epoch 200, ELBO: 13690.983, Slope: 0.003\n",
      "encountered 0 nans\n",
      "Epoch 210, ELBO: 13685.617, Slope: 0.002\n",
      "encountered 0 nans\n",
      "Epoch 220, ELBO: 13701.791, Slope: 0.001\n",
      "encountered 0 nans\n",
      "pass 1\n",
      "Epoch 230, ELBO: 13633.582, Slope: 0.001\n",
      "encountered 0 nans\n",
      "pass 2\n",
      "Epoch 240, ELBO: 13651.408, Slope: 0.000\n",
      "encountered 0 nans\n",
      "pass 3\n",
      "Epoch 250, ELBO: 13681.192, Slope: -0.000\n",
      "encountered 0 nans\n",
      "pass 4\n",
      "fail 1\n",
      "Epoch 260, ELBO: 13672.170, Slope: -0.000\n",
      "encountered 0 nans\n",
      "pass 5\n",
      "Epoch 270, ELBO: 13673.132, Slope: 0.000\n",
      "encountered 0 nans\n",
      "Updating hyperparameters...\n",
      "Updating posterior...\n",
      "Epoch 0, ELBO: 13304.420, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 10, ELBO: 13361.281, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 20, ELBO: 13359.811, Slope: 0.002\n",
      "encountered 0 nans\n",
      "Epoch 30, ELBO: 13369.011, Slope: 0.001\n",
      "encountered 1 nans\n",
      "Epoch 40, ELBO: 13376.430, Slope: 0.001\n",
      "encountered 0 nans\n",
      "pass 1\n",
      "Epoch 50, ELBO: 13380.559, Slope: 0.001\n",
      "encountered 1 nans\n",
      "pass 2\n",
      "Epoch 60, ELBO: 13368.449, Slope: 0.001\n",
      "encountered 2 nans\n",
      "pass 3\n",
      "Epoch 70, ELBO: 13384.791, Slope: 0.001\n",
      "encountered 1 nans\n",
      "pass 4\n",
      "Epoch 80, ELBO: 13375.704, Slope: 0.000\n",
      "encountered 2 nans\n",
      "pass 5\n",
      "Epoch 90, ELBO: 13377.096, Slope: 0.000\n",
      "encountered 4 nans\n",
      "Computing model evidence...\n",
      "\n",
      "log evidence: 13374.374\n",
      "\n",
      "Updating hyperparameters...\n",
      "Updating posterior...\n",
      "Epoch 0, ELBO: 14000.812, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 10, ELBO: 14010.544, Slope: 1.000\n",
      "encountered 2 nans\n",
      "pass 1\n",
      "Epoch 20, ELBO: 14012.248, Slope: 0.000\n",
      "encountered 4 nans\n",
      "pass 2\n",
      "Epoch 30, ELBO: 13985.597, Slope: -0.000\n",
      "encountered 8 nans\n",
      "pass 3\n",
      "Epoch 40, ELBO: 13997.994, Slope: -0.000\n",
      "encountered 12 nans\n",
      "pass 4\n",
      "Epoch 50, ELBO: 14015.092, Slope: 0.000\n",
      "encountered 13 nans\n",
      "pass 5\n",
      "Epoch 60, ELBO: 13979.107, Slope: -0.000\n",
      "encountered 14 nans\n",
      "Computing model evidence...\n",
      "\n",
      "log evidence: 14012.033\n",
      "\n",
      "Updating hyperparameters...\n",
      "Updating posterior...\n",
      "Epoch 0, ELBO: 13773.155, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 10, ELBO: 13786.988, Slope: 1.000\n",
      "encountered 20 nans\n",
      "pass 1\n",
      "Epoch 20, ELBO: 13778.582, Slope: 0.000\n",
      "encountered 13 nans\n",
      "pass 2\n",
      "Epoch 30, ELBO: 13753.409, Slope: -0.000\n",
      "encountered 21 nans\n",
      "pass 3\n",
      "Epoch 40, ELBO: 13777.188, Slope: -0.000\n",
      "encountered 25 nans\n",
      "pass 4\n",
      "Epoch 50, ELBO: 13775.745, Slope: -0.000\n",
      "encountered 26 nans\n",
      "pass 5\n",
      "Epoch 60, ELBO: 13788.229, Slope: 0.000\n",
      "encountered 29 nans\n",
      "Computing model evidence...\n",
      "\n",
      "log evidence: 13783.439\n",
      "\n",
      "Updating hyperparameters...\n",
      "Updating posterior...\n",
      "Epoch 0, ELBO: 13971.712, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 10, ELBO: 13967.907, Slope: 1.000\n",
      "encountered 33 nans\n",
      "pass 1\n",
      "Epoch 20, ELBO: 13981.756, Slope: 0.000\n",
      "encountered 35 nans\n",
      "pass 2\n",
      "Epoch 30, ELBO: 13965.985, Slope: -0.000\n",
      "encountered 31 nans\n",
      "pass 3\n",
      "Epoch 40, ELBO: 13986.218, Slope: 0.000\n",
      "encountered 35 nans\n",
      "pass 4\n",
      "Epoch 50, ELBO: 13965.160, Slope: 0.000\n",
      "encountered 34 nans\n",
      "pass 5\n",
      "Epoch 60, ELBO: 13973.027, Slope: 0.000\n",
      "encountered 30 nans\n",
      "Computing model evidence...\n",
      "\n",
      "log evidence: 13945.136\n",
      "\n",
      "Number of parameters: 72\n",
      "Updating posterior...\n",
      "Epoch 0, ELBO: -70756.523, Slope: 1.000\n",
      "encountered 0 nans\n",
      "Epoch 10, ELBO: -32717.719, Slope: 1.000\n",
      "encountered 20 nans\n",
      "Epoch 20, ELBO: -8718.135, Slope: 0.438\n",
      "encountered 4 nans\n"
     ]
    }
   ],
   "source": [
    "# run kfold for each file \n",
    "for file in files:\n",
    "    strain = file.split(\"_\")[0]\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/SET3_Thirdtrial/{file}\")\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "    \n",
    "    # make sure that conditions have at least one measurement\n",
    "    dfs = []\n",
    "    for treatment, df_t in df.groupby(\"Treatments\"):\n",
    "        if df_t.shape[0] > 1:\n",
    "            dfs.append(df_t)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    mono_dfs = []\n",
    "    dfs = []\n",
    "    treatments = []\n",
    "    for treatment, df_i in df.groupby(\"Treatments\"):\n",
    "        # hyphen is only in community conditions\n",
    "        if \"-\" in treatment:\n",
    "            dfs.append(df_i)\n",
    "            # save treatment name without the replicate identifier \n",
    "            treatments.append([treatment.split(\"_\")[0]]*df_i.shape[0])\n",
    "        else:\n",
    "            mono_dfs.append(df_i)\n",
    "    treatments = np.concatenate(treatments)\n",
    "    unique_treatments = np.unique(treatments)\n",
    "    mono_df = pd.concat(mono_dfs)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # init kfold object\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\n",
    "    # keep track of all predictions\n",
    "    all_exp_names = []\n",
    "    all_pred_species = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_stdv = []\n",
    "\n",
    "    # run Kfold \n",
    "    for train_index, test_index in kf.split(unique_treatments):\n",
    "        \n",
    "        # get train df\n",
    "        train_inds = np.in1d(treatments, unique_treatments[train_index])\n",
    "        train_df = df.iloc[train_inds].copy()\n",
    "        train_df = pd.concat((mono_df, train_df))\n",
    "        \n",
    "        # average replicates in the test_df\n",
    "        test_df = []\n",
    "        for test_treatment in unique_treatments[test_index]:\n",
    "            # pull dataframe with all replicates of same test treatment \n",
    "            treatment_inds = np.in1d(treatments, test_treatment)\n",
    "            df_treatment = df.iloc[treatment_inds].copy()\n",
    "            \n",
    "            # get set of unique measurement times\n",
    "            treatment_times = np.unique(df_treatment.Time.values)\n",
    "            \n",
    "            # init dataframe to store averaged values\n",
    "            avg_df = pd.DataFrame()\n",
    "            avg_df['Treatments'] = [test_treatment]*len(treatment_times)\n",
    "            avg_df['Time'] = treatment_times\n",
    "\n",
    "            avg_data = np.zeros([len(treatment_times), len(species)])\n",
    "            for i, time in enumerate(treatment_times):\n",
    "                avg_data[i] = df_treatment.iloc[df_treatment.Time.values==time][species].mean()\n",
    "            avg_df[species] = avg_data\n",
    "            test_df.append(avg_df)\n",
    "        \n",
    "        # combine averaged dataframes for test dataframe\n",
    "        test_df = pd.concat(test_df)\n",
    "\n",
    "        # init model \n",
    "        model = gLV(dataframe=train_df, \n",
    "                    species=species,\n",
    "                    nu2=.001, sigma2=.01)\n",
    "\n",
    "        # init params\n",
    "        model.init_params(sample=False)\n",
    "        print(f\"Number of parameters: {model.n_params}\")\n",
    "\n",
    "        # fit to data \n",
    "        model.fit_posterior_EM()\n",
    "\n",
    "        # predict test data\n",
    "        exp_names, pred_species, true, pred, stdv = predict_df(test_df, species)\n",
    "\n",
    "        # append predictions \n",
    "        all_exp_names = np.append(all_exp_names, exp_names)\n",
    "        all_pred_species = np.append(all_pred_species, pred_species)\n",
    "        all_true = np.append(all_true, true)\n",
    "        all_pred = np.append(all_pred, pred)\n",
    "        all_stdv = np.append(all_stdv, stdv)\n",
    "\n",
    "        # save prediction results to a .csv\n",
    "        kfold_df = pd.DataFrame()\n",
    "        kfold_df['Treatments'] = all_exp_names\n",
    "        kfold_df['species'] = all_pred_species\n",
    "        kfold_df['true'] = all_true\n",
    "        kfold_df['pred'] = all_pred\n",
    "        kfold_df['stdv'] = all_stdv\n",
    "        kfold_df.to_csv(f\"kfold/{strain}_{n_splits}_fold_VI.csv\", index=False)\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain)\n",
    "    plt.savefig(f\"figures/{strain}_{n_splits}_fold_VI.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
