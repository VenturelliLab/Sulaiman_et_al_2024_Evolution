{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcthompson5@ad.wisc.edu/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, linregress\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.model3 import *\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of folds\n",
    "n_splits = 20\n",
    "\n",
    "# import file names\n",
    "files = os.listdir(\"data/SET3_Thirdtrial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(df, species):\n",
    "    \n",
    "    # save measured and predicted values\n",
    "    exp_names = []\n",
    "    pred_species = []\n",
    "    pred = []\n",
    "    stdv = []\n",
    "    true = []\n",
    "\n",
    "    # pull just the community data\n",
    "    test_data = process_df(df, species) \n",
    "\n",
    "    # plot the results\n",
    "    for exp, t_span, Y_m in test_data:\n",
    "\n",
    "        # predict \n",
    "        Y_p, Y_std = model.predict(Y_m, t_span)\n",
    "        \n",
    "        # set NaN to zero\n",
    "        Y_p = np.nan_to_num(Y_p)\n",
    "        Y_std = np.nan_to_num(Y_std)\n",
    "        \n",
    "        ### prediction results for species that were present ###\n",
    "        inds_present = Y_m[0] > 0 \n",
    "        exp_names.append([exp]*sum(inds_present)*(Y_m.shape[0]-1))\n",
    "        pred_species.append(np.tile(np.vstack(species)[inds_present], Y_m.shape[0]-1).T.ravel())\n",
    "        true.append(Y_m[1:,inds_present].ravel())\n",
    "        pred.append(Y_p[1:,inds_present].ravel())\n",
    "        stdv.append(Y_std[1:,inds_present].ravel())\n",
    "                \n",
    "    # concatenate list\n",
    "    exp_names = np.concatenate(exp_names)\n",
    "    pred_species = np.concatenate(pred_species)\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "    stdv = np.concatenate(stdv)\n",
    "        \n",
    "    return exp_names, pred_species, true, pred, stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1147f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 258, Initial regularization: 1.00e-03\n",
      "Loss: 29.841, Residuals: -0.336\n",
      "Loss: 15.817, Residuals: 0.189\n",
      "Loss: 12.964, Residuals: 0.130\n",
      "Loss: 8.996, Residuals: 0.081\n",
      "Loss: 6.676, Residuals: 0.055\n",
      "Loss: 6.154, Residuals: 0.042\n",
      "Loss: 5.757, Residuals: 0.034\n",
      "Loss: 5.264, Residuals: 0.039\n",
      "Loss: 4.945, Residuals: 0.034\n",
      "Loss: 4.913, Residuals: 0.034\n",
      "Loss: 4.865, Residuals: 0.036\n",
      "Loss: 4.804, Residuals: 0.037\n",
      "Loss: 4.689, Residuals: 0.033\n",
      "Loss: 4.485, Residuals: 0.026\n",
      "Loss: 4.451, Residuals: 0.041\n",
      "Loss: 4.384, Residuals: 0.037\n",
      "Loss: 4.265, Residuals: 0.029\n",
      "Loss: 4.230, Residuals: 0.034\n",
      "Loss: 4.164, Residuals: 0.030\n",
      "Loss: 4.054, Residuals: 0.023\n",
      "Loss: 4.051, Residuals: 0.025\n",
      "Loss: 4.010, Residuals: 0.027\n",
      "Loss: 4.002, Residuals: 0.029\n",
      "Loss: 3.935, Residuals: 0.025\n",
      "Loss: 3.933, Residuals: 0.027\n",
      "Loss: 3.854, Residuals: 0.021\n",
      "Loss: 3.852, Residuals: 0.021\n",
      "Loss: 3.851, Residuals: 0.024\n",
      "Loss: 3.807, Residuals: 0.021\n",
      "Loss: 3.807, Residuals: 0.021\n",
      "Optimization terminated successfully.\n",
      "Evidence -73.678\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 5.41e-01\n",
      "Loss: 174.033, Residuals: 0.012\n",
      "Optimization terminated successfully.\n",
      "Evidence 3627.396\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 4.74e-01\n",
      "Loss: 763.778, Residuals: 0.013\n",
      "Optimization terminated successfully.\n",
      "Evidence 4827.028\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 5.40e-01\n",
      "Loss: 977.221, Residuals: 0.010\n",
      "Loss: 973.132, Residuals: 0.014\n",
      "Loss: 965.699, Residuals: 0.014\n",
      "Loss: 954.256, Residuals: 0.016\n",
      "Loss: 952.918, Residuals: 0.015\n",
      "Loss: 940.960, Residuals: 0.014\n",
      "Loss: 940.761, Residuals: 0.015\n",
      "Optimization terminated successfully.\n",
      "Evidence 4947.541\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 5.10e-01\n",
      "Loss: 1019.699, Residuals: 0.015\n",
      "Optimization terminated successfully.\n",
      "Evidence 4965.279\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 5.12e-01\n",
      "Loss: 1017.589, Residuals: 0.016\n",
      "Loss: 1017.383, Residuals: 0.016\n",
      "Optimization terminated successfully.\n",
      "Evidence 4973.608\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 4.92e-01\n",
      "Loss: 1025.152, Residuals: 0.016\n",
      "Loss: 1020.837, Residuals: 0.015\n",
      "Loss: 1013.210, Residuals: 0.014\n",
      "Loss: 1013.057, Residuals: 0.014\n",
      "Optimization terminated successfully.\n",
      "Evidence 4993.421\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 4.44e-01\n",
      "Loss: 1011.261, Residuals: 0.007\n",
      "Loss: 1010.441, Residuals: 0.007\n",
      "Optimization terminated successfully.\n",
      "Evidence 5014.865\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 3.07e-01\n",
      "Loss: 1030.165, Residuals: 0.009\n",
      "Optimization terminated successfully.\n",
      "Evidence 5023.452\n",
      "Updating hyper-parameters...\n",
      "Total samples: 258, Updated regularization: 3.00e-01\n",
      "Loss: 1030.547, Residuals: 0.008\n",
      "Optimization terminated successfully.\n",
      "Evidence 5024.604\n",
      "Pass count  1\n",
      "Total samples: 253, Initial regularization: 1.00e-03\n",
      "Loss: 30.181, Residuals: -0.327\n",
      "Loss: 16.593, Residuals: 0.227\n",
      "Loss: 14.155, Residuals: 0.178\n",
      "Loss: 10.547, Residuals: 0.105\n",
      "Loss: 8.142, Residuals: 0.041\n",
      "Loss: 7.712, Residuals: 0.032\n",
      "Loss: 6.979, Residuals: 0.024\n",
      "Loss: 6.424, Residuals: 0.025\n",
      "Loss: 6.197, Residuals: 0.034\n",
      "Loss: 5.853, Residuals: 0.026\n",
      "Loss: 5.802, Residuals: 0.036\n",
      "Loss: 5.404, Residuals: 0.029\n",
      "Loss: 5.365, Residuals: 0.042\n",
      "Loss: 5.073, Residuals: 0.026\n",
      "Loss: 5.062, Residuals: 0.033\n",
      "Loss: 4.961, Residuals: 0.029\n",
      "Loss: 4.892, Residuals: 0.036\n",
      "Loss: 4.763, Residuals: 0.030\n",
      "Loss: 4.753, Residuals: 0.033\n",
      "Loss: 4.662, Residuals: 0.029\n",
      "Loss: 4.647, Residuals: 0.035\n",
      "Loss: 4.640, Residuals: 0.035\n",
      "Loss: 4.571, Residuals: 0.032\n",
      "Loss: 4.447, Residuals: 0.026\n",
      "Loss: 4.445, Residuals: 0.027\n",
      "Loss: 4.441, Residuals: 0.029\n",
      "Loss: 4.309, Residuals: 0.022\n",
      "Loss: 4.308, Residuals: 0.022\n",
      "Loss: 4.306, Residuals: 0.022\n",
      "Loss: 4.291, Residuals: 0.024\n",
      "Loss: 4.184, Residuals: 0.017\n",
      "Loss: 4.182, Residuals: 0.022\n",
      "Loss: 4.177, Residuals: 0.022\n",
      "Loss: 4.170, Residuals: 0.020\n",
      "Loss: 4.115, Residuals: 0.015\n",
      "Loss: 4.114, Residuals: 0.016\n",
      "Optimization terminated successfully.\n",
      "Evidence -79.398\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 3.99e-01\n",
      "Loss: 178.968, Residuals: 0.002\n",
      "Loss: 176.644, Residuals: 0.005\n",
      "Loss: 175.843, Residuals: 0.010\n",
      "Loss: 169.154, Residuals: 0.016\n",
      "Loss: 169.131, Residuals: 0.016\n",
      "Optimization terminated successfully.\n",
      "Evidence 3491.852\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 3.60e-01\n",
      "Loss: 731.948, Residuals: 0.018\n",
      "Optimization terminated successfully.\n",
      "Evidence 4637.413\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 4.18e-01\n",
      "Loss: 965.343, Residuals: 0.019\n",
      "Optimization terminated successfully.\n",
      "Evidence 4714.195\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 4.33e-01\n",
      "Loss: 995.255, Residuals: 0.015\n",
      "Loss: 986.565, Residuals: 0.017\n",
      "Loss: 985.099, Residuals: 0.018\n",
      "Loss: 972.578, Residuals: 0.016\n",
      "Loss: 972.047, Residuals: 0.017\n",
      "Loss: 967.142, Residuals: 0.016\n",
      "Loss: 959.426, Residuals: 0.015\n",
      "Loss: 959.329, Residuals: 0.015\n",
      "Optimization terminated successfully.\n",
      "Evidence 4764.326\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 3.61e-01\n",
      "Loss: 1002.005, Residuals: 0.016\n",
      "Optimization terminated successfully.\n",
      "Evidence 4776.003\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 3.57e-01\n",
      "Loss: 1004.517, Residuals: 0.015\n",
      "Loss: 1000.662, Residuals: 0.014\n",
      "Loss: 994.459, Residuals: 0.013\n",
      "Loss: 994.296, Residuals: 0.014\n",
      "Optimization terminated successfully.\n",
      "Evidence 4789.062\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 3.16e-01\n",
      "Loss: 1006.273, Residuals: 0.014\n",
      "Loss: 1003.667, Residuals: 0.014\n",
      "Loss: 1003.059, Residuals: 0.014\n",
      "Loss: 998.000, Residuals: 0.013\n",
      "Loss: 997.972, Residuals: 0.013\n",
      "Optimization terminated successfully.\n",
      "Evidence 4799.897\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 2.76e-01\n",
      "Loss: 1002.306, Residuals: 0.010\n",
      "Loss: 1000.444, Residuals: 0.011\n",
      "Optimization terminated successfully.\n",
      "Evidence 4809.248\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 2.16e-01\n",
      "Loss: 1008.101, Residuals: 0.012\n",
      "Optimization terminated successfully.\n",
      "Evidence 4815.339\n",
      "Updating hyper-parameters...\n",
      "Total samples: 253, Updated regularization: 2.10e-01\n",
      "Loss: 1008.220, Residuals: 0.012\n",
      "Optimization terminated successfully.\n",
      "Evidence 4816.087\n",
      "Pass count  1\n",
      "Total samples: 254, Initial regularization: 1.00e-03\n",
      "Loss: 29.784, Residuals: -0.316\n"
     ]
    }
   ],
   "source": [
    "# run kfold for each file \n",
    "for file in files:\n",
    "    strain = file.split(\"_\")[0]\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/SET3_Thirdtrial/{file}\")\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "    \n",
    "    # make sure that conditions have at least one measurement\n",
    "    dfs = []\n",
    "    for treatment, df_t in df.groupby(\"Treatments\"):\n",
    "        if df_t.shape[0] > 1:\n",
    "            dfs.append(df_t)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    mono_dfs = []\n",
    "    dfs = []\n",
    "    treatments = []\n",
    "    for treatment, df_i in df.groupby(\"Treatments\"):\n",
    "        # hyphen is only in community conditions\n",
    "        if \"-\" in treatment:\n",
    "            dfs.append(df_i)\n",
    "            # save treatment name without the replicate identifier \n",
    "            treatments.append([treatment.split(\"_\")[0]]*df_i.shape[0])\n",
    "        else:\n",
    "            mono_dfs.append(df_i)\n",
    "    treatments = np.concatenate(treatments)\n",
    "    unique_treatments = np.unique(treatments)\n",
    "    mono_df = pd.concat(mono_dfs)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # init kfold object\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\n",
    "    # keep track of all predictions\n",
    "    all_exp_names = []\n",
    "    all_pred_species = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_stdv = []\n",
    "\n",
    "    # run Kfold \n",
    "    for train_index, test_index in kf.split(unique_treatments):\n",
    "        \n",
    "        # get train df\n",
    "        train_inds = np.in1d(treatments, unique_treatments[train_index])\n",
    "        train_df = df.iloc[train_inds].copy()\n",
    "        train_df = pd.concat((mono_df, train_df))\n",
    "        \n",
    "        # average replicates in the test_df\n",
    "        test_df = []\n",
    "        for test_treatment in unique_treatments[test_index]:\n",
    "            # pull dataframe with all replicates of same test treatment \n",
    "            treatment_inds = np.in1d(treatments, test_treatment)\n",
    "            df_treatment = df.iloc[treatment_inds].copy()\n",
    "            \n",
    "            # get set of unique measurement times\n",
    "            treatment_times = np.unique(df_treatment.Time.values)\n",
    "            \n",
    "            # init dataframe to store averaged values\n",
    "            avg_df = pd.DataFrame()\n",
    "            avg_df['Treatments'] = [test_treatment]*len(treatment_times)\n",
    "            avg_df['Time'] = treatment_times\n",
    "\n",
    "            avg_data = np.zeros([len(treatment_times), len(species)])\n",
    "            for i, time in enumerate(treatment_times):\n",
    "                avg_data[i] = df_treatment.iloc[df_treatment.Time.values==time][species].mean()\n",
    "            avg_df[species] = avg_data\n",
    "            test_df.append(avg_df)\n",
    "        \n",
    "        # combine averaged dataframes for test dataframe\n",
    "        test_df = pd.concat(test_df)\n",
    "        \n",
    "        # instantiate gLV fit \n",
    "        model = gLV(species, train_df)\n",
    "\n",
    "        # fit to data \n",
    "        model.fit()\n",
    "\n",
    "        # plot fitness to data\n",
    "        exp_names, pred_species, true, pred, stdv = predict_df(test_df, species)\n",
    "\n",
    "        # append predictions \n",
    "        all_exp_names = np.append(all_exp_names, exp_names)\n",
    "        all_pred_species = np.append(all_pred_species, pred_species)\n",
    "        all_true = np.append(all_true, true)\n",
    "        all_pred = np.append(all_pred, pred)\n",
    "        all_stdv = np.append(all_stdv, stdv)\n",
    "\n",
    "        # save prediction results to a .csv\n",
    "        kfold_df = pd.DataFrame()\n",
    "        kfold_df['Treatments'] = all_exp_names\n",
    "        kfold_df['species'] = all_pred_species\n",
    "        kfold_df['true'] = all_true\n",
    "        kfold_df['pred'] = all_pred\n",
    "        kfold_df['stdv'] = all_stdv\n",
    "        kfold_df.to_csv(f\"kfold/{strain}_{n_splits}_fold_3.csv\", index=False)\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain)\n",
    "    plt.savefig(f\"figures/{strain}_{n_splits}_fold_3.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
