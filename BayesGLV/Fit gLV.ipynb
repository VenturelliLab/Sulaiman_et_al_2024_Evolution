{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, pearsonr\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CDanc_CDmono12h_PROVIDET0.csv', 'CDevo_CDmono12h_PROVIDET0.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import file names\n",
    "files = os.listdir(\"data/SET3_Thirdtrial/\")\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9af71ae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 271, Initial regularization: 1.00e-03\n",
      "Loss: 31.853, Residuals: -0.285\n",
      "Loss: 16.700, Residuals: 0.148\n",
      "Loss: 14.154, Residuals: 0.080\n",
      "Loss: 10.455, Residuals: 0.044\n",
      "Loss: 8.596, Residuals: 0.010\n",
      "Loss: 8.314, Residuals: 0.030\n",
      "Loss: 7.838, Residuals: 0.025\n",
      "Loss: 7.272, Residuals: 0.032\n",
      "Loss: 7.174, Residuals: 0.037\n",
      "Loss: 7.010, Residuals: 0.034\n",
      "Loss: 6.964, Residuals: 0.043\n",
      "Loss: 6.878, Residuals: 0.039\n",
      "Loss: 6.732, Residuals: 0.033\n",
      "Loss: 6.698, Residuals: 0.041\n",
      "Loss: 6.635, Residuals: 0.038\n",
      "Loss: 6.530, Residuals: 0.031\n",
      "Loss: 6.510, Residuals: 0.038\n",
      "Loss: 6.473, Residuals: 0.035\n",
      "Loss: 6.406, Residuals: 0.030\n",
      "Loss: 6.402, Residuals: 0.036\n",
      "Loss: 6.361, Residuals: 0.032\n",
      "Loss: 6.287, Residuals: 0.026\n",
      "Loss: 6.278, Residuals: 0.026\n",
      "Loss: 6.200, Residuals: 0.020\n",
      "Loss: 6.199, Residuals: 0.023\n",
      "Loss: 6.186, Residuals: 0.023\n",
      "Loss: 6.161, Residuals: 0.020\n",
      "Loss: 6.133, Residuals: 0.018\n",
      "Loss: 6.128, Residuals: 0.021\n",
      "Loss: 6.090, Residuals: 0.015\n",
      "Loss: 6.089, Residuals: 0.015\n",
      "Loss: 6.087, Residuals: 0.015\n",
      "Loss: 6.069, Residuals: 0.011\n",
      "Loss: 6.067, Residuals: 0.012\n",
      "Loss: 6.064, Residuals: 0.012\n",
      "Loss: 6.059, Residuals: 0.011\n",
      "Loss: 6.050, Residuals: 0.008\n",
      "Loss: 6.049, Residuals: 0.009\n",
      "Loss: 6.048, Residuals: 0.009\n",
      "Loss: 6.046, Residuals: 0.008\n",
      "Loss: 6.041, Residuals: 0.007\n",
      "Loss: 6.040, Residuals: 0.006\n",
      "Loss: 6.038, Residuals: 0.006\n",
      "Loss: 6.038, Residuals: 0.006\n",
      "Loss: 6.036, Residuals: 0.006\n",
      "Loss: 6.033, Residuals: 0.005\n",
      "Loss: 6.033, Residuals: 0.005\n",
      "Loss: 6.032, Residuals: 0.005\n",
      "Loss: 6.029, Residuals: 0.005\n",
      "Loss: 6.028, Residuals: 0.005\n",
      "Loss: 6.028, Residuals: 0.005\n",
      "Loss: 6.027, Residuals: 0.005\n",
      "Loss: 6.026, Residuals: 0.005\n",
      "Loss: 6.025, Residuals: 0.006\n",
      "Loss: 6.024, Residuals: 0.006\n",
      "Loss: 6.023, Residuals: 0.006\n",
      "Loss: 6.023, Residuals: 0.006\n",
      "Loss: 6.022, Residuals: 0.006\n",
      "Loss: 6.021, Residuals: 0.006\n",
      "Loss: 6.021, Residuals: 0.006\n",
      "Loss: 6.021, Residuals: 0.006\n",
      "Loss: 6.020, Residuals: 0.006\n",
      "Loss: 6.019, Residuals: 0.006\n",
      "Loss: 6.019, Residuals: 0.006\n",
      "Loss: 6.019, Residuals: 0.006\n",
      "Loss: 6.019, Residuals: 0.006\n",
      "Loss: 6.018, Residuals: 0.005\n",
      "Loss: 6.018, Residuals: 0.005\n",
      "Loss: 6.018, Residuals: 0.005\n",
      "Loss: 6.017, Residuals: 0.005\n",
      "Loss: 6.017, Residuals: 0.005\n",
      "Loss: 6.017, Residuals: 0.005\n",
      "Loss: 6.017, Residuals: 0.005\n",
      "Loss: 6.016, Residuals: 0.005\n",
      "Loss: 6.016, Residuals: 0.005\n",
      "Loss: 6.016, Residuals: 0.005\n",
      "Loss: 6.016, Residuals: 0.005\n",
      "Loss: 6.016, Residuals: 0.005\n",
      "Loss: 6.016, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.015, Residuals: 0.005\n",
      "Loss: 6.014, Residuals: 0.005\n",
      "Loss: 6.014, Residuals: 0.005\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.005\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.014, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Loss: 6.013, Residuals: 0.004\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "Evidence -75.332\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 3.77e-01\n",
      "Loss: 262.390, Residuals: 0.008\n",
      "Optimization terminated successfully.\n",
      "Evidence 3781.336\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 4.07e-01\n",
      "Loss: 955.072, Residuals: 0.011\n",
      "Optimization terminated successfully.\n",
      "Evidence 4662.871\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 4.31e-01\n",
      "Loss: 1026.532, Residuals: -0.000\n",
      "Loss: 1022.240, Residuals: -0.007\n",
      "Loss: 1014.676, Residuals: -0.007\n",
      "Loss: 1003.903, Residuals: -0.005\n",
      "Loss: 995.553, Residuals: -0.001\n",
      "Loss: 995.167, Residuals: -0.000\n",
      "Optimization terminated successfully.\n",
      "Evidence 4761.909\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 4.39e-01\n",
      "Loss: 1077.001, Residuals: 0.001\n",
      "Optimization terminated successfully.\n",
      "Evidence 4800.283\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 4.39e-01\n",
      "Loss: 1076.227, Residuals: -0.001\n",
      "Loss: 1073.627, Residuals: -0.004\n",
      "Loss: 1069.179, Residuals: -0.003\n",
      "Loss: 1062.414, Residuals: -0.000\n",
      "Loss: 1061.968, Residuals: 0.000\n",
      "Loss: 1058.257, Residuals: -0.000\n",
      "Loss: 1057.924, Residuals: -0.000\n",
      "Loss: 1054.867, Residuals: 0.000\n",
      "Loss: 1054.799, Residuals: 0.000\n",
      "Optimization terminated successfully.\n",
      "Evidence 4830.179\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 4.81e-01\n",
      "Loss: 1081.217, Residuals: 0.002\n",
      "Optimization terminated successfully.\n",
      "Evidence 4835.745\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 4.81e-01\n",
      "Loss: 1081.777, Residuals: -0.000\n",
      "Loss: 1076.497, Residuals: 0.000\n",
      "Loss: 1076.137, Residuals: 0.001\n",
      "Loss: 1075.462, Residuals: 0.001\n",
      "Loss: 1074.176, Residuals: 0.001\n",
      "Loss: 1071.809, Residuals: -0.000\n",
      "Loss: 1071.139, Residuals: -0.001\n",
      "Loss: 1070.968, Residuals: -0.001\n",
      "Loss: 1069.391, Residuals: -0.001\n",
      "Loss: 1066.813, Residuals: -0.002\n",
      "Loss: 1066.553, Residuals: -0.002\n",
      "Loss: 1066.128, Residuals: -0.002\n",
      "Loss: 1065.973, Residuals: -0.002\n",
      "Loss: 1065.677, Residuals: -0.002\n",
      "Loss: 1065.119, Residuals: -0.002\n",
      "Loss: 1064.928, Residuals: -0.002\n",
      "Optimization terminated successfully.\n",
      "Evidence 4854.854\n",
      "Updating hyper-parameters...\n",
      "Total samples: 271, Updated regularization: 5.56e-01\n",
      "Loss: 1081.536, Residuals: -0.002\n",
      "Optimization terminated successfully.\n",
      "Evidence 4857.063\n",
      "Pass count  1\n",
      "Total samples: 225, Initial regularization: 1.00e-03\n",
      "Loss: 29.262, Residuals: -0.286\n",
      "Loss: 11.591, Residuals: 0.156\n",
      "Loss: 9.143, Residuals: 0.065\n",
      "Loss: 5.861, Residuals: 0.039\n",
      "Loss: 4.062, Residuals: 0.033\n",
      "Loss: 3.380, Residuals: 0.034\n",
      "Loss: 3.249, Residuals: 0.037\n",
      "Loss: 3.020, Residuals: 0.026\n",
      "Loss: 2.701, Residuals: 0.013\n",
      "Loss: 2.662, Residuals: 0.020\n",
      "Loss: 2.591, Residuals: 0.017\n",
      "Loss: 2.477, Residuals: 0.011\n",
      "Loss: 2.471, Residuals: 0.019\n",
      "Loss: 2.418, Residuals: 0.017\n",
      "Loss: 2.325, Residuals: 0.011\n",
      "Loss: 2.309, Residuals: 0.018\n",
      "Loss: 2.286, Residuals: 0.020\n",
      "Loss: 2.243, Residuals: 0.017\n",
      "Loss: 2.240, Residuals: 0.020\n",
      "Loss: 2.207, Residuals: 0.018\n",
      "Loss: 2.153, Residuals: 0.013\n",
      "Loss: 2.147, Residuals: 0.016\n",
      "Loss: 2.098, Residuals: 0.010\n",
      "Loss: 2.091, Residuals: 0.011\n",
      "Loss: 2.081, Residuals: 0.010\n",
      "Loss: 2.061, Residuals: 0.008\n",
      "Loss: 2.044, Residuals: 0.007\n",
      "Loss: 2.043, Residuals: 0.009\n",
      "Loss: 2.032, Residuals: 0.008\n",
      "Loss: 2.029, Residuals: 0.007\n",
      "Loss: 2.007, Residuals: 0.004\n",
      "Loss: 2.007, Residuals: 0.004\n",
      "Loss: 1.997, Residuals: 0.002\n",
      "Loss: 1.997, Residuals: 0.003\n",
      "Loss: 1.985, Residuals: 0.001\n",
      "Loss: 1.984, Residuals: 0.001\n",
      "Loss: 1.975, Residuals: -0.001\n",
      "Loss: 1.975, Residuals: -0.001\n",
      "Loss: 1.970, Residuals: -0.002\n",
      "Loss: 1.962, Residuals: -0.004\n",
      "Loss: 1.962, Residuals: -0.004\n",
      "Loss: 1.962, Residuals: -0.004\n",
      "Loss: 1.961, Residuals: -0.004\n",
      "Loss: 1.958, Residuals: -0.005\n",
      "Loss: 1.958, Residuals: -0.005\n",
      "Loss: 1.958, Residuals: -0.005\n",
      "Loss: 1.958, Residuals: -0.005\n",
      "Loss: 1.957, Residuals: -0.005\n",
      "Loss: 1.956, Residuals: -0.005\n",
      "Loss: 1.955, Residuals: -0.006\n",
      "Loss: 1.955, Residuals: -0.006\n",
      "Loss: 1.955, Residuals: -0.006\n",
      "Loss: 1.953, Residuals: -0.007\n",
      "Loss: 1.953, Residuals: -0.007\n",
      "Loss: 1.953, Residuals: -0.007\n",
      "Loss: 1.953, Residuals: -0.007\n",
      "Loss: 1.953, Residuals: -0.007\n",
      "Loss: 1.953, Residuals: -0.007\n",
      "Loss: 1.952, Residuals: -0.007\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.952, Residuals: -0.008\n",
      "Loss: 1.951, Residuals: -0.008\n",
      "Loss: 1.951, Residuals: -0.008\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Loss: 1.951, Residuals: -0.009\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "Evidence -54.160\n",
      "Updating hyper-parameters...\n",
      "Total samples: 225, Updated regularization: 3.58e-01\n",
      "Loss: 115.822, Residuals: -0.013\n",
      "Loss: 105.910, Residuals: -0.003\n",
      "Loss: 105.800, Residuals: -0.003\n",
      "Optimization terminated successfully.\n",
      "Evidence 3320.302\n",
      "Updating hyper-parameters...\n",
      "Total samples: 225, Updated regularization: 5.97e-01\n",
      "Loss: 649.234, Residuals: -0.002\n",
      "Optimization terminated successfully.\n",
      "Evidence 4615.825\n",
      "Updating hyper-parameters...\n",
      "Total samples: 225, Updated regularization: 6.90e-01\n",
      "Loss: 871.647, Residuals: -0.008\n",
      "Loss: 865.753, Residuals: -0.008\n",
      "Loss: 858.056, Residuals: -0.009\n",
      "Loss: 857.601, Residuals: -0.009\n",
      "Loss: 853.923, Residuals: -0.008\n",
      "Loss: 853.869, Residuals: -0.008\n",
      "Optimization terminated successfully.\n",
      "Evidence 4707.683\n",
      "Updating hyper-parameters...\n",
      "Total samples: 225, Updated regularization: 6.80e-01\n",
      "Loss: 895.966, Residuals: -0.008\n",
      "Loss: 895.464, Residuals: -0.008\n",
      "Loss: 894.502, Residuals: -0.008\n",
      "Loss: 892.788, Residuals: -0.008\n",
      "Loss: 890.432, Residuals: -0.008\n",
      "Loss: 890.381, Residuals: -0.008\n",
      "Optimization terminated successfully.\n",
      "Evidence 4721.057\n",
      "Updating hyper-parameters...\n",
      "Total samples: 225, Updated regularization: 6.77e-01\n",
      "Loss: 898.639, Residuals: -0.008\n",
      "Optimization terminated successfully.\n",
      "Evidence 4722.235\n",
      "Pass count  1\n"
     ]
    }
   ],
   "source": [
    "exp_names = []\n",
    "for file in files:\n",
    "    # define strain name\n",
    "    strain = file.split(\"_\")[0]\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/SET3_Thirdtrial/{file}\")\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "    \n",
    "    # make sure that conditions have at least one measurement\n",
    "    dfs = []\n",
    "    for treatment, df_t in df.groupby(\"Treatments\"):\n",
    "        if df_t.shape[0] > 1:\n",
    "            dfs.append(df_t)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # instantiate gLV fit \n",
    "    model = gLV(species, df)\n",
    "\n",
    "    # fit to data \n",
    "    model.fit()\n",
    "    \n",
    "    # list of parameter names \n",
    "    param_names = []\n",
    "    for s1 in species:\n",
    "        for s2 in species:\n",
    "            param_names += [s1+\"*\"+s2]\n",
    "    param_names = list(species) + param_names\n",
    "    \n",
    "    # plot parameter distribution\n",
    "    n_species = len(species)\n",
    "    Avec = model.params[n_species:]\n",
    "    Aij_std = np.sqrt(np.diag(model.Ainv))[n_species:]\n",
    "\n",
    "    plt.figure(figsize=(18,18))\n",
    "    # set counter for parameter std. \n",
    "    k = 0\n",
    "\n",
    "    for i in range(n_species):\n",
    "        for j in range(n_species):\n",
    "            plt.subplot(n_species, n_species, k+1)\n",
    "            a = np.linspace(Avec[k]-np.std(Avec), Avec[k]+np.std(Avec))\n",
    "            plt.plot(a, norm.pdf(a,Avec[k],Aij_std[k]))\n",
    "            plt.axvline(x=0, c='k', alpha=.5)\n",
    "            k += 1\n",
    "            if j == 0:\n",
    "                plt.ylabel(species[i], fontsize=18)\n",
    "            if i == n_species-1:\n",
    "                plt.xlabel(species[j], fontsize=18)\n",
    "            #plt.xlim([-2,2])\n",
    "    \n",
    "    plt.suptitle(strain, fontsize=24)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(\"params/SET3/\"+strain+\".pdf\")\n",
    "    plt.close()\n",
    "    \n",
    "    # compute Wald test for each parameter\n",
    "    std_errors = np.sqrt(np.diag(model.Ainv))\n",
    "    walds = model.params/std_errors\n",
    "    wald_p_vals = 2*norm.cdf(-np.abs(walds))\n",
    "\n",
    "    # save to df \n",
    "    df = pd.DataFrame()\n",
    "    df[\"Param name\"] = param_names\n",
    "    df[\"Param value\"] = model.params\n",
    "    df[\"Param stdv\"]  = np.sqrt(np.diag(model.Ainv))\n",
    "    df[\"Param p-value\"] = wald_p_vals\n",
    "    for j, param_name in enumerate(param_names):\n",
    "        df[param_name]  = model.Ainv[:, j]\n",
    "    df.to_csv(\"params/SET3/\"+strain+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd6a1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Param name</th>\n",
       "      <th>Param value</th>\n",
       "      <th>Param stdv</th>\n",
       "      <th>Param p-value</th>\n",
       "      <th>CA</th>\n",
       "      <th>BT</th>\n",
       "      <th>BU</th>\n",
       "      <th>CD</th>\n",
       "      <th>BV</th>\n",
       "      <th>CS</th>\n",
       "      <th>...</th>\n",
       "      <th>DP*DP</th>\n",
       "      <th>DP*CH</th>\n",
       "      <th>CH*CA</th>\n",
       "      <th>CH*BT</th>\n",
       "      <th>CH*BU</th>\n",
       "      <th>CH*CD</th>\n",
       "      <th>CH*BV</th>\n",
       "      <th>CH*CS</th>\n",
       "      <th>CH*DP</th>\n",
       "      <th>CH*CH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>0.322340</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>2.784668e-47</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-2.816653e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BT</td>\n",
       "      <td>0.888700</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>3.376683e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BU</td>\n",
       "      <td>0.922836</td>\n",
       "      <td>0.015662</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.687107e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CD</td>\n",
       "      <td>0.667217</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>3.521316e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000224</td>\n",
       "      <td>-0.000435</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>-0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BV</td>\n",
       "      <td>0.742756</td>\n",
       "      <td>0.011865</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>1.000210e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>CH*CD</td>\n",
       "      <td>-1.413961</td>\n",
       "      <td>0.180350</td>\n",
       "      <td>4.501759e-15</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>2.156658e-08</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000908</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.016569</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.032526</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>-0.018848</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.001579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>CH*BV</td>\n",
       "      <td>-0.412560</td>\n",
       "      <td>0.046379</td>\n",
       "      <td>5.824234e-19</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>3.070108e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.001720</td>\n",
       "      <td>-0.011916</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>-0.005611</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>CH*CS</td>\n",
       "      <td>3.503119</td>\n",
       "      <td>0.863483</td>\n",
       "      <td>4.971465e-05</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-8.379646e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>0.019046</td>\n",
       "      <td>-0.009213</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>-0.009843</td>\n",
       "      <td>-0.018848</td>\n",
       "      <td>-0.005611</td>\n",
       "      <td>0.745603</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>0.002674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>CH*DP</td>\n",
       "      <td>-3.333008</td>\n",
       "      <td>0.457497</td>\n",
       "      <td>3.209300e-13</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-5.085356e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002342</td>\n",
       "      <td>0.036120</td>\n",
       "      <td>-0.041177</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>-0.000892</td>\n",
       "      <td>0.017392</td>\n",
       "      <td>0.004517</td>\n",
       "      <td>-0.072078</td>\n",
       "      <td>0.209304</td>\n",
       "      <td>0.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>CH*CH</td>\n",
       "      <td>-0.928677</td>\n",
       "      <td>0.036888</td>\n",
       "      <td>7.357584e-140</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>2.529513e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>-0.000928</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.001361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Param name  Param value  Param stdv  Param p-value        CA        BT  \\\n",
       "0          CA     0.322340    0.022318   2.784668e-47  0.000498  0.000008   \n",
       "1          BT     0.888700    0.014790   0.000000e+00  0.000008  0.000219   \n",
       "2          BU     0.922836    0.015662   0.000000e+00  0.000022  0.000081   \n",
       "3          CD     0.667217    0.013464   0.000000e+00  0.000015  0.000005   \n",
       "4          BV     0.742756    0.011865   0.000000e+00  0.000019  0.000031   \n",
       "..        ...          ...         ...            ...       ...       ...   \n",
       "67      CH*CD    -1.413961    0.180350   4.501759e-15  0.000049  0.000023   \n",
       "68      CH*BV    -0.412560    0.046379   5.824234e-19 -0.000019  0.000009   \n",
       "69      CH*CS     3.503119    0.863483   4.971465e-05  0.000442  0.000025   \n",
       "70      CH*DP    -3.333008    0.457497   3.209300e-13  0.000342  0.000036   \n",
       "71      CH*CH    -0.928677    0.036888  7.357584e-140 -0.000020 -0.000001   \n",
       "\n",
       "          BU        CD        BV            CS  ...     DP*DP     DP*CH  \\\n",
       "0   0.000022  0.000015  0.000019 -2.816653e-06  ...  0.000009  0.000206   \n",
       "1   0.000081  0.000005  0.000031  3.376683e-08  ...  0.000006  0.000053   \n",
       "2   0.000245  0.000032  0.000078  1.687107e-06  ... -0.000046  0.000010   \n",
       "3   0.000032  0.000181  0.000021  3.521316e-06  ... -0.000224 -0.000435   \n",
       "4   0.000078  0.000021  0.000141  1.000210e-06  ... -0.000034  0.000009   \n",
       "..       ...       ...       ...           ...  ...       ...       ...   \n",
       "67  0.000071  0.000343 -0.000101  2.156658e-08  ... -0.000908 -0.001300   \n",
       "68  0.000017 -0.000016 -0.000045  3.070108e-07  ... -0.000013 -0.001720   \n",
       "69  0.000073  0.000221  0.000153 -8.379646e-05  ...  0.001165  0.019046   \n",
       "70  0.000180  0.000488 -0.000323 -5.085356e-06  ... -0.002342  0.036120   \n",
       "71 -0.000020 -0.000014 -0.000058  2.529513e-07  ...  0.000044 -0.000928   \n",
       "\n",
       "       CH*CA     CH*BT     CH*BU     CH*CD     CH*BV     CH*CS     CH*DP  \\\n",
       "0  -0.000014  0.000007 -0.000017  0.000049 -0.000019  0.000442  0.000342   \n",
       "1  -0.000056  0.000185  0.000016  0.000023  0.000009  0.000025  0.000036   \n",
       "2  -0.000131 -0.000009  0.000046  0.000071  0.000017  0.000073  0.000180   \n",
       "3   0.000068 -0.000016 -0.000010  0.000343 -0.000016  0.000221  0.000488   \n",
       "4   0.000258 -0.000018 -0.000023 -0.000101 -0.000045  0.000153 -0.000323   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "67 -0.016569  0.001082  0.000538  0.032526  0.002655 -0.018848  0.017392   \n",
       "68 -0.011916  0.000506 -0.000064  0.002655  0.002151 -0.005611  0.004517   \n",
       "69 -0.009213  0.000555 -0.009843 -0.018848 -0.005611  0.745603 -0.072078   \n",
       "70 -0.041177  0.003112 -0.000892  0.017392  0.004517 -0.072078  0.209304   \n",
       "71  0.000003  0.000518  0.000349  0.001579  0.000444  0.002674  0.004062   \n",
       "\n",
       "       CH*CH  \n",
       "0  -0.000020  \n",
       "1  -0.000001  \n",
       "2  -0.000020  \n",
       "3  -0.000014  \n",
       "4  -0.000058  \n",
       "..       ...  \n",
       "67  0.001579  \n",
       "68  0.000444  \n",
       "69  0.002674  \n",
       "70  0.004062  \n",
       "71  0.001361  \n",
       "\n",
       "[72 rows x 76 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
