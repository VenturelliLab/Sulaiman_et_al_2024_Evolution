{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaron/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/home/jaron/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n",
      "/tmp/ipykernel_2774/672834334.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-rmkl0sod because the default path (/home/jaron/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, linregress\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove.model3 import *\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of folds\n",
    "n_splits = 20\n",
    "\n",
    "# import file names\n",
    "files = os.listdir(\"data/SET3_Thirdtrial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104c6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(df, species):\n",
    "    \n",
    "    # save measured and predicted values\n",
    "    exp_names = []\n",
    "    pred_species = []\n",
    "    pred = []\n",
    "    stdv = []\n",
    "    true = []\n",
    "\n",
    "    # pull just the community data\n",
    "    test_data = process_df(df, species) \n",
    "\n",
    "    # plot the results\n",
    "    for exp, t_span, Y_m in test_data:\n",
    "\n",
    "        # predict \n",
    "        Y_p, Y_std = model.predict(Y_m, t_span)\n",
    "        \n",
    "        # set NaN to zero\n",
    "        Y_p = np.nan_to_num(Y_p)\n",
    "        Y_std = np.nan_to_num(Y_std)\n",
    "        \n",
    "        ### prediction results for species that were present ###\n",
    "        inds_present = Y_m[0] > 0 \n",
    "        exp_names.append([exp]*sum(inds_present)*(Y_m.shape[0]-1))\n",
    "        pred_species.append(np.tile(np.vstack(species)[inds_present], Y_m.shape[0]-1).T.ravel())\n",
    "        true.append(Y_m[1:,inds_present].ravel())\n",
    "        pred.append(Y_p[1:,inds_present].ravel())\n",
    "        stdv.append(Y_std[1:,inds_present].ravel())\n",
    "                \n",
    "    # concatenate list\n",
    "    exp_names = np.concatenate(exp_names)\n",
    "    pred_species = np.concatenate(pred_species)\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "    stdv = np.concatenate(stdv)\n",
    "        \n",
    "    return exp_names, pred_species, true, pred, stdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1147f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 258, Initial regularization: 1.00e-03\n"
     ]
    }
   ],
   "source": [
    "# run kfold for each file \n",
    "for file in files:\n",
    "    strain = file.split(\"_\")[0]\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/SET3_Thirdtrial/{file}\")\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "    \n",
    "    # make sure that conditions have at least one measurement\n",
    "    dfs = []\n",
    "    for treatment, df_t in df.groupby(\"Treatments\"):\n",
    "        if df_t.shape[0] > 1:\n",
    "            dfs.append(df_t)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    mono_dfs = []\n",
    "    dfs = []\n",
    "    treatments = []\n",
    "    for treatment, df_i in df.groupby(\"Treatments\"):\n",
    "        # hyphen is only in community conditions\n",
    "        if \"-\" in treatment:\n",
    "            dfs.append(df_i)\n",
    "            # save treatment name without the replicate identifier \n",
    "            treatments.append([treatment.split(\"_\")[0]]*df_i.shape[0])\n",
    "        else:\n",
    "            mono_dfs.append(df_i)\n",
    "    treatments = np.concatenate(treatments)\n",
    "    unique_treatments = np.unique(treatments)\n",
    "    mono_df = pd.concat(mono_dfs)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # init kfold object\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\n",
    "    # keep track of all predictions\n",
    "    all_exp_names = []\n",
    "    all_pred_species = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_stdv = []\n",
    "\n",
    "    # run Kfold \n",
    "    for train_index, test_index in kf.split(unique_treatments):\n",
    "        \n",
    "        # get train df\n",
    "        train_inds = np.in1d(treatments, unique_treatments[train_index])\n",
    "        train_df = df.iloc[train_inds].copy()\n",
    "        train_df = pd.concat((mono_df, train_df))\n",
    "        \n",
    "        # average replicates in the test_df\n",
    "        test_df = []\n",
    "        for test_treatment in unique_treatments[test_index]:\n",
    "            # pull dataframe with all replicates of same test treatment \n",
    "            treatment_inds = np.in1d(treatments, test_treatment)\n",
    "            df_treatment = df.iloc[treatment_inds].copy()\n",
    "            \n",
    "            # get set of unique measurement times\n",
    "            treatment_times = np.unique(df_treatment.Time.values)\n",
    "            \n",
    "            # init dataframe to store averaged values\n",
    "            avg_df = pd.DataFrame()\n",
    "            avg_df['Treatments'] = [test_treatment]*len(treatment_times)\n",
    "            avg_df['Time'] = treatment_times\n",
    "\n",
    "            avg_data = np.zeros([len(treatment_times), len(species)])\n",
    "            for i, time in enumerate(treatment_times):\n",
    "                avg_data[i] = df_treatment.iloc[df_treatment.Time.values==time][species].mean()\n",
    "            avg_df[species] = avg_data\n",
    "            test_df.append(avg_df)\n",
    "        \n",
    "        # combine averaged dataframes for test dataframe\n",
    "        test_df = pd.concat(test_df)\n",
    "        \n",
    "        # instantiate gLV fit \n",
    "        model = gLV(species, train_df)\n",
    "\n",
    "        # fit to data \n",
    "        model.fit()\n",
    "\n",
    "        # plot fitness to data\n",
    "        exp_names, pred_species, true, pred, stdv = predict_df(test_df, species)\n",
    "\n",
    "        # append predictions \n",
    "        all_exp_names = np.append(all_exp_names, exp_names)\n",
    "        all_pred_species = np.append(all_pred_species, pred_species)\n",
    "        all_true = np.append(all_true, true)\n",
    "        all_pred = np.append(all_pred, pred)\n",
    "        all_stdv = np.append(all_stdv, stdv)\n",
    "\n",
    "        # save prediction results to a .csv\n",
    "        kfold_df = pd.DataFrame()\n",
    "        kfold_df['Treatments'] = all_exp_names\n",
    "        kfold_df['species'] = all_pred_species\n",
    "        kfold_df['true'] = all_true\n",
    "        kfold_df['pred'] = all_pred\n",
    "        kfold_df['stdv'] = all_stdv\n",
    "        kfold_df.to_csv(f\"kfold/{strain}_{n_splits}_fold_3.csv\", index=False)\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "        plt.errorbar(all_true[sp_inds], all_pred[sp_inds], yerr=all_stdv[sp_inds], \n",
    "                     fmt='.', capsize=3)\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain)\n",
    "    plt.savefig(f\"figures/{strain}_{n_splits}_fold_3.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
