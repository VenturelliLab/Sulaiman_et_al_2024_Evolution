{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm, linregress\n",
    "\n",
    "import os\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from glove_VI.glv3 import *\n",
    "\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06280f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of folds\n",
    "n_splits = 20\n",
    "\n",
    "# number of inner folds\n",
    "n_splits_2 = 10\n",
    "\n",
    "# range of L1 coefs\n",
    "lmbdas = np.array([0., .000001, .00001, .0001, .001])\n",
    "\n",
    "# number of training epochs\n",
    "n_epochs = 200\n",
    "\n",
    "# import file names\n",
    "files = os.listdir(\"data/SET3_Thirdtrial/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f66f683",
   "metadata": {},
   "source": [
    "# fit gLV models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_df(model, df, species):\n",
    "    \n",
    "    # save measured and predicted values\n",
    "    exp_names = []\n",
    "    pred_species = []\n",
    "    pred = []\n",
    "    true = []\n",
    "\n",
    "    # pull just the community data\n",
    "    test_data = process_df_glove(df, species) \n",
    "\n",
    "    # plot the results\n",
    "    for exp, t_span, Y_m in test_data:\n",
    "\n",
    "        # predict \n",
    "        Y_p = model.predict_point(Y_m, t_span)\n",
    "        \n",
    "        # set NaN to zero\n",
    "        Y_p = np.nan_to_num(Y_p)\n",
    "        \n",
    "        ### prediction results for species that were present ###\n",
    "        inds_present = Y_m[0] > 0 \n",
    "        exp_names.append([exp]*sum(inds_present)*(Y_m.shape[0]-1))\n",
    "        pred_species.append(np.tile(np.vstack(species)[inds_present], Y_m.shape[0]-1).T.ravel())\n",
    "        true.append(Y_m[1:,inds_present].ravel())\n",
    "        pred.append(Y_p[1:,inds_present].ravel())\n",
    "                \n",
    "    # concatenate list\n",
    "    exp_names = np.concatenate(exp_names)\n",
    "    pred_species = np.concatenate(pred_species)\n",
    "    true = np.concatenate(true)\n",
    "    pred = np.concatenate(pred)\n",
    "        \n",
    "    return exp_names, pred_species, true, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb880b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_lmbda(df):\n",
    "    \n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    mono_dfs = []\n",
    "    dfs = []\n",
    "    treatments = []\n",
    "    for treatment, df_i in df.groupby(\"Treatments\"):\n",
    "        # hyphen is only in community conditions\n",
    "        if \"-\" in treatment:\n",
    "            dfs.append(df_i)\n",
    "            # save treatment name without the replicate identifier \n",
    "            treatments.append([treatment.split(\"_\")[0]]*df_i.shape[0])\n",
    "        else:\n",
    "            mono_dfs.append(df_i)\n",
    "    treatments = np.concatenate(treatments)\n",
    "    unique_treatments = np.unique(treatments)\n",
    "    mono_df = pd.concat(mono_dfs)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # init vector of prediction performances\n",
    "    performances = np.zeros(len(lmbdas))\n",
    "        \n",
    "    # scan range of lmbdas\n",
    "    for lmbda_idx, lmbda in enumerate(lmbdas):\n",
    "    \n",
    "        # init kfold object\n",
    "        kf = KFold(n_splits=n_splits_2, shuffle=True, random_state=21)\n",
    "\n",
    "        # keep track of all predictions\n",
    "        all_exp_names = []\n",
    "        all_pred_species = []\n",
    "        all_true = []\n",
    "        all_pred = []\n",
    "\n",
    "        # run Kfold \n",
    "        for kf_idx, (train_index, test_index) in enumerate(kf.split(unique_treatments)):\n",
    "\n",
    "            # get train df\n",
    "            train_inds = np.in1d(treatments, unique_treatments[train_index])\n",
    "            train_df = df.iloc[train_inds].copy()\n",
    "            train_df = pd.concat((mono_df, train_df))\n",
    "\n",
    "            # average replicates in the test_df\n",
    "            test_df = []\n",
    "            for test_treatment in unique_treatments[test_index]:\n",
    "                # pull dataframe with all replicates of same test treatment \n",
    "                treatment_inds = np.in1d(treatments, test_treatment)\n",
    "                df_treatment = df.iloc[treatment_inds].copy()\n",
    "\n",
    "                # get set of unique measurement times\n",
    "                treatment_times = np.unique(df_treatment.Time.values)\n",
    "\n",
    "                # init dataframe to store averaged values\n",
    "                avg_df = pd.DataFrame()\n",
    "                avg_df['Treatments'] = [test_treatment]*len(treatment_times)\n",
    "                avg_df['Time'] = treatment_times\n",
    "\n",
    "                avg_data = np.zeros([len(treatment_times), len(species)])\n",
    "                for i, time in enumerate(treatment_times):\n",
    "                    avg_data[i] = df_treatment.iloc[df_treatment.Time.values==time][species].mean()\n",
    "                avg_df[species] = avg_data\n",
    "                test_df.append(avg_df)\n",
    "\n",
    "            # combine averaged dataframes for test dataframe\n",
    "            test_df = pd.concat(test_df)\n",
    "\n",
    "            # init model \n",
    "            model = gLV(dataframe=train_df, \n",
    "                        species=species,\n",
    "                        lmbda=lmbda)\n",
    "\n",
    "            # fit to data \n",
    "            print(f\"Inner Fold {kf_idx+1}, L1: {lmbda}\")\n",
    "            f = model.fit_rmse(epochs=n_epochs)\n",
    "\n",
    "            # plot fitness to data\n",
    "            exp_names, pred_species, true, pred = predict_df(model, test_df, species)\n",
    "            \n",
    "            # append predictions \n",
    "            all_exp_names = np.append(all_exp_names, exp_names)\n",
    "            all_pred_species = np.append(all_pred_species, pred_species)\n",
    "            all_true = np.append(all_true, true)\n",
    "            all_pred = np.append(all_pred, pred)\n",
    "\n",
    "        # show prediction performance of individual species\n",
    "        r_values = []\n",
    "        for sp in species:\n",
    "            sp_inds = all_pred_species == sp\n",
    "            r_values.append(linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue)\n",
    "\n",
    "        # save performance\n",
    "        performances[lmbda_idx] = np.mean(r_values)\n",
    "        \n",
    "        # print performance and lmbda\n",
    "        print(f\"L1: {lmbda}, avg r: {np.mean(r_values)}\")\n",
    "        \n",
    "    # return best lmbda\n",
    "    return lmbdas[np.argmax(performances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1147f18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run kfold for each file \n",
    "for file in files:\n",
    "    strain = file.split(\"_\")[0]\n",
    "    \n",
    "    # import data\n",
    "    df = pd.read_csv(f\"data/SET3_Thirdtrial/{file}\")\n",
    "    df.sort_values(by=[\"Treatments\", \"Time\"], inplace=True)\n",
    "    \n",
    "    # make sure that conditions have at least one measurement\n",
    "    dfs = []\n",
    "    for treatment, df_t in df.groupby(\"Treatments\"):\n",
    "        if df_t.shape[0] > 1:\n",
    "            dfs.append(df_t)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # determine species names \n",
    "    species = df.columns.values[2:]\n",
    "\n",
    "    # separate mono culture data \n",
    "    mono_dfs = []\n",
    "    dfs = []\n",
    "    treatments = []\n",
    "    for treatment, df_i in df.groupby(\"Treatments\"):\n",
    "        # hyphen is only in community conditions\n",
    "        if \"-\" in treatment:\n",
    "            dfs.append(df_i)\n",
    "            # save treatment name without the replicate identifier \n",
    "            treatments.append([treatment.split(\"_\")[0]]*df_i.shape[0])\n",
    "        else:\n",
    "            mono_dfs.append(df_i)\n",
    "    treatments = np.concatenate(treatments)\n",
    "    unique_treatments = np.unique(treatments)\n",
    "    mono_df = pd.concat(mono_dfs)\n",
    "    df = pd.concat(dfs)\n",
    "\n",
    "    # init kfold object\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=21)\n",
    "\n",
    "    # keep track of all predictions\n",
    "    all_exp_names = []\n",
    "    all_pred_species = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "\n",
    "    # run Kfold \n",
    "    for kf_idx, (train_index, test_index) in enumerate(kf.split(unique_treatments)):\n",
    "        \n",
    "        # get train df\n",
    "        train_inds = np.in1d(treatments, unique_treatments[train_index])\n",
    "        train_df = df.iloc[train_inds].copy()\n",
    "        train_df = pd.concat((mono_df, train_df))\n",
    "        \n",
    "        # average replicates in the test_df\n",
    "        test_df = []\n",
    "        for test_treatment in unique_treatments[test_index]:\n",
    "            # pull dataframe with all replicates of same test treatment \n",
    "            treatment_inds = np.in1d(treatments, test_treatment)\n",
    "            df_treatment = df.iloc[treatment_inds].copy()\n",
    "            \n",
    "            # get set of unique measurement times\n",
    "            treatment_times = np.unique(df_treatment.Time.values)\n",
    "            \n",
    "            # init dataframe to store averaged values\n",
    "            avg_df = pd.DataFrame()\n",
    "            avg_df['Treatments'] = [test_treatment]*len(treatment_times)\n",
    "            avg_df['Time'] = treatment_times\n",
    "\n",
    "            avg_data = np.zeros([len(treatment_times), len(species)])\n",
    "            for i, time in enumerate(treatment_times):\n",
    "                avg_data[i] = df_treatment.iloc[df_treatment.Time.values==time][species].mean()\n",
    "            avg_df[species] = avg_data\n",
    "            test_df.append(avg_df)\n",
    "        \n",
    "        # combine averaged dataframes for test dataframe\n",
    "        test_df = pd.concat(test_df)\n",
    "        \n",
    "        # optimize lambda using kfold on training data (nested kfold)\n",
    "        lmbda = optimize_lmbda(train_df)\n",
    "        print(f\"Strain {strain}, Outer Fold {kf_idx+1}, L1: {lmbda}\")\n",
    "        \n",
    "        # init model \n",
    "        model = gLV(dataframe=train_df, \n",
    "                    species=species,\n",
    "                    lmbda=lmbda)\n",
    "\n",
    "        # fit to data \n",
    "        f = model.fit_rmse(epochs=n_epochs)\n",
    "\n",
    "        # plot fitness to data\n",
    "        exp_names, pred_species, true, pred = predict_df(model, test_df, species)\n",
    "\n",
    "        # append predictions \n",
    "        all_exp_names = np.append(all_exp_names, exp_names)\n",
    "        all_pred_species = np.append(all_pred_species, pred_species)\n",
    "        all_true = np.append(all_true, true)\n",
    "        all_pred = np.append(all_pred, pred)\n",
    "\n",
    "        # save prediction results to a .csv\n",
    "        kfold_df = pd.DataFrame()\n",
    "        kfold_df['Treatments'] = all_exp_names\n",
    "        kfold_df['species'] = all_pred_species\n",
    "        kfold_df['true'] = all_true\n",
    "        kfold_df['pred'] = all_pred\n",
    "        kfold_df.to_csv(f\"kfold/{strain}_{n_splits}_fold_3.csv\", index=False)\n",
    "        \n",
    "    # show prediction performance of individual species\n",
    "    for sp in species:\n",
    "        sp_inds = all_pred_species == sp\n",
    "        R = linregress(all_true[sp_inds], all_pred[sp_inds]).rvalue\n",
    "        plt.scatter(all_true[sp_inds], all_pred[sp_inds], label=f\"{sp} \" + \"R={:.3f}\".format(R))\n",
    "\n",
    "    plt.xlabel(\"Measured OD\")\n",
    "    plt.ylabel(\"Predicted OD\")\n",
    "    plt.legend()\n",
    "    plt.title(strain)\n",
    "    plt.savefig(f\"figures/{strain}_{n_splits}_fold_3.pdf\", dpi=300)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
